---
title: "Bayesian Analysis of Vertical Configuration, For Preregistration"
author: "Alex Holcombe"
date: "8/06/2019"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

For an experiment in which in one condition, two letters are presented in vertical configuration, and in other condition, two words are presented in vertical configuration (half of trials in left visual field and half in right visual field, but will probably collapse across the two visual fields for most of these analyses).

The prereg of the experiment with the incorrect (due to programming error) vertical alignment is [here](https://osf.io/jpy58).


To inform the prior for the size of the letters top advantage, we will use the previously-published vertical results.

#### Considerations for the prior on the effect size

In E1 (horizontally arrayed letters versus horizontally arrayed words), the left advantage of the letters was smaller than in all previous experiments, which is a bit worrying. It could be a fluke, or it could be because of half of Ss just done the words which givs a big right hemifield advantage, or it could be the oral response. All additional reasons to be conservative.

Another difference with our previous work is that in this experiment both streams are in one or the other hemisphere.

### Previous effect sizes

```{r, echo=FALSE}
#E1, E2 refers to Holcombe Nguyen Goodbourn E1, E2
E1n<- 16
#Raw effect size plus standard error and sd
P1E1canonical=.23;  P1E1c_se = .058; P1E1c_sd = P1E1c_se * sqrt(E1n)
P1E1reversed= .062;  P1E1r_se = .07; P1E1r_sd = P1E1r_se * sqrt(E1n)
#To calculate sd of the bias diff, consider that the variances sum,
#therefore first sum the variances then convert back to standard deviation
#Although only true for *independent* random variables and these unlikely to be totally independent

E2n<- 24
P1E2canonical=.218; P1E2c_se =.034; P1E2c_sd= P1E2c_se * sqrt(E2n)
P1E2inverted=.017; P1E2i_se =.049; P1E2i_sd = P1E2i_se * sqrt(E2n)

P1E2vertUpright=.188; P1E2vu_se=.043; P1E2vu_sd = P1E2vu_se * sqrt(E2n)
P1E2vertInverted= -.07; P1E2vi_se=.049; P1E2vi_sd = P1E2vi_se * sqrt(E2n)

cohensDsHoriz<-c(P1E1canonical/P1E1c_sd,
                 P1E2canonical/P1E2c_sd) 
cohensDsHorizLabels<-c("HolNguGoodE1horiz","HolNguGoodE2horiz")
```

For the HolcombeNguyenGoodbourn paper? For E1 (horizontal),`r P1E1canonical` in the canonical orientation and 
`r P1E1reversed` for mirror-reversed. For E2 (vertical) `r P1E2canonical` for canonical horizontal orientation.

For E2 vertical arrangement, letters rotated to face down, `r P1E2vertUpright` and for letters facing up, `r P1E2vertInverted`.


```{r HolcombeGoodbourn, echo = FALSE}
#Figure 4a
#Looks like for HolcombeNguyenGoodbourn the effect size calculations above are all of the difference scores, not the individual sides
# vertical difference d = 1.74, 95% CI [0.30, 0.50].  This is taken straight from the results section.
HolGoodVertCohensD = 1.74

```

For Holcombe & Goodbourn, vertical upper advantage was Cohen's d of `r HolGoodVertCohensD`.

### Calculating the mode of the prior for the effect size for letters and words

Average the results from Holcombe Nguyen & Goodbourn (backwards paper) E2 because that had the vertical configuration, with Goodbourn & Holcombe (2015) vertical configuration. The letters in the Holcombe Nguyen & Goodbourn experiment were rotated to face downwards or upwards, so weight the Goodbourn & Holcombe effect more highly, yielding a *predicted value for the letter upper bias of*
```{r, echo=FALSE}


cohensDs<-c(HolGoodVertCohensD,
            P1E2vertUpright / P1E2vu_sd) 
print(cohensDs)
cohensDslabels<-c("HolGoodVert", "HolNguGoodVert")
meanCohensD<-cohensDs[[1]]*.7 + cohensDs[[2]]*.3  #mean(cohensDs)

modalEffectLtrs = meanCohensD
```
`r modalEffectLtrs`

This value will be the mode of our prior, but of course there is plenty of uncertainty about what the true effect size might be even under this theory, so we will have a wide distribution.

The words arguably have a greater left-to-right implication than individual letters, suggesting the words effect will be smaller than the letters effect. On the other hand, the words could kick reading processes more than individual letters, suggesting it could be an even greater effect. On the third hand, the letters bias is already so much bigger than conventional effects in psychology that it's not likely that it would be bigger, this third hand weighs the balance slightly toward smaller effects, so we can expect that the effect will be smaller than the usual letters effect,
```{r, echo=FALSE}
wordHandicap=.84
```
by a factor of `r wordHandicap`. Also it's much less certain than the letters so should make the sigmas bigger, which we'll do later.

```{r handicapWords, echo=FALSE}
wordPredictedCohensD<- meanCohensD * wordHandicap
```

As a result we are predicting (the mode of our prior) that the Cohen's d for the words condition upper bias is `r wordPredictedCohensD`.

## Constructing the prior distribution and density (normalized distribution)

For the shape of the prior, we will use what I call a "double Gaussian" with different sd to the left of mode than to the right of the mode (later it will be rescaled to make it a density).

For the width of the prior, to be honest it is hard to know how to set a Gaussian sigma (width of the prior) because how much to think of the previous estimates as estimating the same thing versus being actually different effects? Setting it to the sd of the previous results looks too small. By trial and error with eyeball I arrived at sigma on each side of
```{r}
sigmaLeft =.93
sigmaRight = .5
```

This is based on wanting right of the mode of the distribution to be thin-tailed (because the true effect is almost definitely not enormous, like greater than 2.5) while the left side to be heavier (because the effect might well end up being hella closer to zero), I will use two half-Gaussians with different standard deviations. 

```{r, echo=FALSE}
#Create doubleGaussian ,and vectorize it because common functions like plot require it , otherwise you have to use mapply

doubleGaussian = function(xs, mean,sdLeft,sdRight) {
  #print(length(x))  # Most plotting functions send this a million numbers rather than one
  #A double gaussian is two half-gaussians with different sigmas. But to make them match up, I have to calculate the peak height of each and then rescale. The peak height is of course its value at the mean. I will scale each so that it peaks at 1.
  #It will then be rescaled later to make it a proper density function that integrates to 1.
  leftXs <- xs[xs<=mean]
  rightXs <- xs[xs>mean]
  Ys<-c()
  if (length(leftXs) >0) {
    leftPeakHeight = dnorm(mean,mean,sdLeft)
    Ys <- dnorm(leftXs,mean,sdLeft) / leftPeakHeight
  }
  if (length(rightXs) >0) {
    rightPeakHeight = dnorm(mean,mean,sdRight)
    rightYs <- dnorm(rightXs,mean,sdRight) / rightPeakHeight
    Ys <- c(Ys,rightYs)
  }
  Ys
}

myDoubleGaussian = function(x) {
  doubleGaussian(x,0,2,1)
}

#Test that myDoubleGaussian is working.

myDoubleGaussian(3)
```
Plot doubleGaussian graphs to make sure it's working.
```{r, echo=FALSE}

#My doubleGaussian function is not vectorized so I can't use normal way of plotting. Maybe I should vectorize, but that would be a good deal of work.
#https://stackoverflow.com/questions/44730774/how-to-use-custom-functions-in-mutate-dplyr

library("dplyr")
df <- data.frame(x=seq(-1,1,.01))
#df<- df %>% mutate(density=  mapply(function(x) myDoubleGaussian(x), x))
df<- df %>% mutate(density=myDoubleGaussian(x))

library('ggplot2')
ggplot(df, aes(x=x,y=density)) + geom_line() + xlab("x") +theme_bw()
```


```{r }

#Set up my prior, a double Gaussian, making it a function of just one parameter, the x value
doubleGaussianLtrs = function(x) {
  doubleGaussian(x,modalEffectLtrs,sigmaLeft,sigmaRight)
}
```

Create integrable function for the prior
```{r lettersPrior}
#Specify hypothesis, technically alternative hypothesis (up to constant of proportionality) for letters
lo=0 #lower bound of support
hi=Inf #upper bound of support

#Define integrable prior - must be function of only the integrand
altHypothesisLtrs=function(delta) {
  y= doubleGaussianLtrs(delta)
  y=y*as.integer(delta>lo)*as.integer(delta<hi) #multiply by zero if outside of support
}

```

```{r }
#Normalize alternative density in case is not already
#Calculate normalization factor - fraction to multiply prior by so it will integrate to 1
K=1/integrate(altHypothesisLtrs,lower=lo,upper=hi)$value 

#Thus final prior is the normalized function
priorLtrs=function(delta) K*altHypothesisLtrs(delta)
```

Plot the letters prior, a DoubleGaussian distribution with our mean observed effect (as a Cohen's d), `r modalEffectLtrs` and sigma left of mode=`r sigmaLeft` and sigma right of mode=`r sigmaRight`.

```{r, echo=FALSE}
dDomain=seq(0,3,.01) #density domain

#Plot Alternative as a density and Null as a point arrow
maxAlt = priorLtrs(modalEffectLtrs) #maxAlt=max(priorLtrs(dDomain))

plot(dDomain,priorLtrs(dDomain),typ='n',xlab="Reading-direction bias (Cohen's d) for letters",ylab="Density",ylim=c(0,max(1,1.4*maxAlt)),main=)
#typ 'n' means invisible, and it's the lines command that actually plots the points.
arrows(0,0,0,1,col='darkblue',lwd=2)
lines(dDomain,priorLtrs(dDomain),col='green',lwd=2)
legend("topright",legend=c("Null","Alternative","Previous findings"),col=c('darkblue','green','black'),lwd=2)
points(cohensDs, rep(.1,length(cohensDs)),pch=19) #plot previous vertical effect sizes
text(cohensDs, c(.2,.27), cohensDslabels,cex=.75)

points(cohensDsHoriz, rep(.1,length(cohensDsHoriz)),pch=21,col="grey",bg="grey") #plot previous horizontal arrangement effect sizes
text(cohensDsHoriz, c(.02,.06), cohensDsHorizLabels,cex=.75, col="grey")

```

```{r}
sigmaLeftWords = sigmaLeft
sigmaRightWords = 0.9
```
In contrast to the letters, prior for the words will be  a DoubleGaussian distribution with our mean observed effect (as a Cohen's d), `r wordPredictedCohensD` and sigma left of mode=`r sigmaLeft` and sigma right of mode=`r sigmaRight`.

```{r wordsPrior}
#Specify hypothesis, technically alternative hypothesis (up to constant of proportionality) for words

#Set up mhy prior, a double Gaussian, making it a function of just one parameter, the x value
myDoubleGaussian = function(x) {
  doubleGaussian(x,wordPredictedCohensD,sigmaLeftWords,sigmaRightWords)
}

#Specify hypothesis, technically alternative hypothesis (up to constant of proportionality) for letters
lo=0 #lower bound of support
hi=Inf #upper bound of support

#Define integrable prior - must be function of only the integrand
altHypothesis=function(delta) {
  y= myDoubleGaussian(delta)
  y=y*as.integer(delta>lo)*as.integer(delta<hi) #multiply by zero if outside of support
}

#Normalize alternative density in case is not already
#Calculate normalization factor - fraction to multiply prior by so it will integrate to 1
K=1/integrate(altHypothesis,lower=lo,upper=hi)$value 

#Thus final prior is the normalized function
priorWords=function(delta) K*altHypothesis(delta)
```

Plot the words prior

```{r, echo=FALSE}

#delta=seq(-.2,1.2,.01)

dDomain=seq(-.3,2.5,.01)

#Plot Alternative as a density and Null as a point arrow
maxAlt=max(priorWords(dDomain))
plot(dDomain,priorWords(dDomain),typ='n',xlab="Top bias (Cohen's d)",ylab="Density",ylim=c(0,1),main="Words and letters top bias prior")
arrows(0,0,0,1,col='darkblue',lwd=2)
lines(dDomain,priorWords(dDomain),col='yellow',lwd=3)
lines(dDomain,priorLtrs(dDomain),col='green',lwd=2)

legend("topright",legend=c("Null","AlternativeLtrs","AlternativeWords","Previous findings"),col=c('darkblue','green','yellow','black'),lwd=2)

points(cohensDs, rep(.1,length(cohensDs)),pch=19) #plot previous vertical effect sizes
text(cohensDs, c(.17,.17), cohensDslabels,cex=.75)

points(cohensDsHoriz, rep(.1,length(cohensDsHoriz)), pch=21,col="grey",bg="grey") #plot previous horizontal arrangement effect sizes
text(cohensDsHoriz, c(.02,.06), cohensDsHorizLabels, cex=.75, col="grey")
```

When the data come in, will calculate the Cohen's d and then for each Cohen's d in the prior, calculate the probability of the data, integrating over the entire prior. That average likelihood (probability of the data under the alternative hypothesis) will be compared to probability of the data under the null hypothesis.

## Do Bayesian t-test. 

That is, take the likelihood of the left bias difference observed under the prior and divide it by the likelihood of the left bias difference observed under the null.

http://jeffrouder.blogspot.com.au/2016/01/what-priors-should-i-use-part-i.html
For the null model, the bias is just zero (delta function).For our model, support is zero to infinity. 

Probably best to do it in the standardized units (Cohen's d) I've been using because otherwise need to create a model of the variance separately (for the data model) so that can calculate the probability of the data given e.g. the null hypothesis.

## Latency and precision predictions

Broad prediction is that the latency for top and bottom will be similar for letters and words and close to zero. Historically we have seen a small non-significantly higher latency in the horizontal configuration for the right visual field, for example 10 ms in HolNguGood downward condition (13 vs 23 ms), while that particular paper didn't have a latency difference for horizontal conditions. Thus a 10 ms difference is compatible with the letters condition. And not big enough to be expected if attentional shift was going on. THEREFORE DO A SLAB NULL PRIOR THAT INCLUDES 10 MS?

## Correlogram predictions

We consistently with letters observed zero correlation, except when we placed the letters very close to each other (unpublished honours thesis by Xiaoqi "Cheryl" Xu)

## Predicted: no effect of report order


## Bayes factor computation

Is it ok to model everything as if it is a one-sample design, which is what Rouder's blog post was written for?  Because this isn't a one-sample experiment of course, instead there's an efficacy for the top position and of the bottom position. Yes because I turned it into a difference score.  And it's not like we're doing this only to simplify  for a custom Bayesian, Kim actually did that with JASP for other reasons.

"If we take a sample of n observations from a normal distribution, then the t-distribution with n-1 degrees of freedom can be defined as the distribution of the location of the sample mean relative to the true mean, divided by the sample standard deviation, after multiplying by the standardizing term sqrt(n)." - Wikipedia.


## Probability of any particular effect size according to these priors

The predicted density of data for the null is related to the central t distribution. 

So assuming that the top bias is normally distributed between participants, we can use the t.
n refers to the number of participants, and the sample standard deviation is the standard deviation of the participant effects.

In R,
dt(x, df, ncp, log = FALSE) Density for the t distribution with df degrees of freedom (and optional non-centrality parameter ncp).

```{r}
nullPredF=function(obs,N) {
  dt(sqrt(N)*obs,N-1)
}
```

Compute this predicted density for any observed effect size or for all of them. The following code does it for a reasonable range of effect sizes for a sample size of 
```{r}
obs<-seq(-.2,2.1,.01)
numSs<- 40
nullPred<- nullPredF(obs,numSs)
```
`r numSs`

Getting the predictive density for the alternative is a bit harder (Rouder). For each nonzero effect size parameter, the distribution of the observed effect follows a noncentral t distribution. Hence, to obtain predictions across all nonzero effect size parameters, we need to integrate the alternative model against the noncentral t distribution. 

```{r, echo=FALSE}
altPredIntegrand = function(delta,obs,N) {
  dt( sqrt(N)*obs, N-1, sqrt(N)*delta ) * priorWords(delta)
}

#For a particular effect size, obs, and a particular number of participants, calcuate the likelihood of it
altPredF = function(obs,N) {
  integrate( altPredIntegrand, lower=lo, upper=hi, obs=obs, N=N )$value
}
```

Now calculate the likelihood of every effect size. 

Seemingly every time it's called, it yields this warning, so I've suppressed warnings for now.

> Warning in dt(sqrt(N) * obs, N - 1, sqrt(N) * delta): full precision may not have been achieved in 'pnt{final}'

```{r, echo=FALSE, warning=FALSE}
I=length(obs)
altPred=1:I #Place to put the likelihoods
for (i in 1:I) {
  altPred[i]=altPredF(obs[i],numSs)
}
```

Now we can plot the predictions for all observed effect sizes

```{r}

top=max(altPred,nullPred)
tit<- paste('Predictions (n=',numSs,')')
plot(type='l',obs,nullPred,ylim=c(0,top),xlab="Observed Effect Size",ylab="Density",main=tit,col='darkblue',lwd=2)
lines(obs,altPred,col='darkgreen',lwd=2)
legend("topright",legend=c("Null","AlternativeWords"),col=c('darkblue','darkgreen'),lwd=2)
points(cohensDs, rep(.1,length(cohensDs)),pch=19) #plot previous vertical effect sizes
text(cohensDs, c(.17,.17), cohensDslabels,cex=.75)

points(cohensDsHoriz, rep(.1,length(cohensDsHoriz)), pch=21,col="grey",bg="grey") #plot previous horizontal arrangement effect sizes
text(cohensDsHoriz, c(.02,.06), cohensDsHorizLabels, cex=.75, col="grey")
```

I can't explain why the notch occurs in the alternative hypothesis.


## Secondary research questions (not part of the main theory)

3. Whether the top bias depends on whether the streams are presented in the left or right hemifield. 
To the extent that there is a top bias, smaller capacity limit in one hemisphere, as suggested by so-and-so, could create a greater top bias.

The difference in efficacy between upper and lower streams for both letters and words depends on whether the streams are presented in the left or right visual field. STATISTICAL TEST: Compare top bias in LVF to top bias in RVF. Bayesian t-test should do it because I'm expecting a quite small effect size so the default psychology prior should be fine.

4. Previous research that has investigated lateral biases in word recognition has tended to find better performance for words presented to the right visual field, though studies that have measured this using nonwords or letter strings have found mixed results.  Overall performance may be better in the right visual field, especially for the words.

STATISTICAL TEST: ANOVA with Average efficacy  (of top and bottom) as d.v. and two factors: visual field and words versus letters.

